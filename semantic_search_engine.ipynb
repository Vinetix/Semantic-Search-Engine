{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Jf8T6yV-tmVK"
      },
      "outputs": [],
      "source": [
        "# Install the necessary libraries\n",
        "!pip install sentence-transformers datasets faiss-cpu pandas numpy rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULyt1uDit0Aw"
      },
      "source": [
        "#**ENVIRONMENT SETUP & DATA INGESTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "eee6717898564fc29a4318accb9c31b1",
            "ad07d18d928a498889d706d9291337e2",
            "15a298ba8b6546f0bcd353ff0f2d422a",
            "f2a0572ecf544c01a94dca7c1cc0c390",
            "f15ac723b858477b994ac338d2c3d647",
            "bc3cfa0ce55e45248b81d981515a5ae4",
            "03e63a09f3ac40ef941dc19d34f9e37f",
            "319e491c6a584f08a90a6352b707024d",
            "eab6fa02363a490fb05f7a0f4d3d7e4e",
            "b7bf86e06feb483aa7717e6b5661c40a",
            "652429a3d0734aa3b51d3774c83ba7bf"
          ]
        },
        "id": "zxPYLA4at5qm",
        "outputId": "32fd8dea-6000-4148-90b3-29290669c084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime Device: cuda\n",
            "Initializing MS MARCO stream...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eee6717898564fc29a4318accb9c31b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting 10000 samples...\n",
            "Data Extraction Complete.\n",
            "Queries: 10000 | Corpus Size: 82193 | Qrels: 9701\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import pandas as pd\n",
        "import faiss\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses, util\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Reproducibility Setup\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(42)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Runtime Device: {device}\")\n",
        "\n",
        "# Data Ingestion (Streaming)\n",
        "# Using streaming=True to handle 8.8M dataset with limited RAM\n",
        "print(\"Initializing MS MARCO stream...\")\n",
        "dataset_stream = load_dataset('ms_marco', 'v1.1', split='train', streaming=True)\n",
        "\n",
        "# Configuration\n",
        "CORPUS_LIMIT = 10000 # Limit to 10k docs for rapid prototyping/debugging\n",
        "corpus_ids = set()\n",
        "corpus_data = []\n",
        "queries = []\n",
        "qrels = {}\n",
        "\n",
        "print(f\"Extracting {CORPUS_LIMIT} samples...\")\n",
        "counter = 0\n",
        "\n",
        "for sample in dataset_stream:\n",
        "    if counter >= CORPUS_LIMIT:\n",
        "        break\n",
        "\n",
        "    q_id = sample['query_id']\n",
        "    q_text = sample['query']\n",
        "    queries.append({'id': q_id, 'text': q_text})\n",
        "\n",
        "    # Extract relevant/non-relevant passages\n",
        "    passages = sample['passages']\n",
        "    for idx, text in enumerate(passages['passage_text']):\n",
        "        is_correct = passages['is_selected'][idx]\n",
        "\n",
        "        # Synthesize unique doc_id since streaming doesn't guarantee global uniqueness order\n",
        "        doc_id = f\"doc_{counter}_{idx}\"\n",
        "\n",
        "        if doc_id not in corpus_ids:\n",
        "            corpus_data.append({'id': doc_id, 'text': text})\n",
        "            corpus_ids.add(doc_id)\n",
        "\n",
        "        if is_correct:\n",
        "            qrels[q_id] = doc_id # Map Query -> Correct Doc\n",
        "\n",
        "    counter += 1\n",
        "\n",
        "# Structuring data\n",
        "df_corpus = pd.DataFrame(corpus_data)\n",
        "df_queries = pd.DataFrame(queries)\n",
        "\n",
        "print(f\"Data Extraction Complete.\\nQueries: {len(df_queries)} | Corpus Size: {len(df_corpus)} | Qrels: {len(qrels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKICJILXuGnt"
      },
      "source": [
        "#**BASELINE MODEL IMPLEMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEsVOzTSuNPq"
      },
      "outputs": [],
      "source": [
        "# Baseline Model Initialization\n",
        "print(\"Loading Pre-trained MiniLM...\")\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "# Corpus Encoding\n",
        "# Batch encoding on GPU for speed\n",
        "print(\"Encoding Baseline Corpus...\")\n",
        "doc_text_list = df_corpus['text'].tolist()\n",
        "doc_embeddings = model.encode(doc_text_list, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "# FAISS Index Construction\n",
        "# Normalization handled by model output; IP equivalent to Cosine Similarity\n",
        "dimension = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "print(f\"Baseline Index Built. Total Vectors: {index.ntotal}\")\n",
        "\n",
        "# Search Utility\n",
        "def search_pipeline(query, model_obj, index_obj, k=10):\n",
        "    \"\"\"\n",
        "    Executes dense retrieval: Query Encode -> Vector Search -> Result Parsing\n",
        "    \"\"\"\n",
        "    q_vec = model_obj.encode([query], convert_to_numpy=True)\n",
        "    D, I = index_obj.search(q_vec, k)\n",
        "\n",
        "    results = []\n",
        "    for idx, score in zip(I[0], D[0]):\n",
        "        doc_data = df_corpus.iloc[idx]\n",
        "        results.append({\n",
        "            'score': float(score),\n",
        "            'id': doc_data['id'],\n",
        "            'text': doc_data['text']\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Sanity Check\n",
        "print(\"\\n--- Baseline Sanity Check ---\")\n",
        "test_res = search_pipeline(\"what is the capital of australia\", model, index)\n",
        "print(f\"Top Result: {test_res[0]['text'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArTcQe4Ku650"
      },
      "source": [
        "#**FINE TUNING (HARD NEGATIVES)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "87599eedcf7b48aeab82c357b1d987d2",
            "4b8aca147e40415a93692417403eabdb",
            "00f66749fbb94d5088d731b666077493",
            "5373e9dab7bf4b1b852d7866f321e4af",
            "061544a1ed43470285906d06bd44c2db",
            "f8a586c561034341bce71c4dd43e062d",
            "2fcb68bda69b417e8a5d5454820017eb",
            "60e3e38a52784829be42cc93443a3b9d",
            "15e2b33be6b642ef9c0fc787e07617e0",
            "0639bfed980f424a926bf82227fb3432",
            "ef4d8eb6ba0640e9b32fc88f9d737a78",
            "5a5f12f5f14f42c1afb8b025f8fe63ed",
            "ff0a51f568264a44b9997232c080011c",
            "8f22c793f6704ae88b77b8b758e950ee",
            "f1d343020f2943fe82ae4dce70d54158",
            "8a454c20ef144f8380da114e9267dd6e",
            "f6a67ff39c754ad78929bf59c5d37858",
            "f1a1916442de484aa41f33ab0570d6d3",
            "8603a9bf536e493eae4e756a0277ca5a",
            "d6cdbaa4a81a4b0c99c3c743cc435034",
            "5b0c0fbead34438cabbcd4bc38e43227",
            "6a4d4fa0f297423297659632da08e336",
            "73625775856048d2a8a039a4d3637d3e",
            "29c1837d11ab4d61afd26704152810d2",
            "35523b8e45954a81b93d07e9e34239ac",
            "4d34157303f54e7a80ea297dc2afd55b",
            "8146e0ef2729406cba7229e35c4892d7",
            "7495434f51c749dabbde2b8ec1e23c59",
            "f5e0e335c8db4d64bc485a5b99fe4dde",
            "b452b464fd7d4498acab96f1b2d7761a",
            "bb74197e76d647ceb95c2ea7805c2d9f",
            "26041ed795da47d7b0c5ac5d651b754b",
            "7a9ecc08cb014f37854ed87441994268"
          ]
        },
        "id": "1Gfkg7Y8vEJu",
        "outputId": "d4b8b706-5d8c-4f7c-b616-335d355fa05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mining Hard Negatives from Baseline...\n",
            "Generated 1000 triplets for training.\n",
            "Executing Fine-Tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87599eedcf7b48aeab82c357b1d987d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:09, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a5f12f5f14f42c1afb8b025f8fe63ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73625775856048d2a8a039a4d3637d3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-Tuned Model Loaded.\n"
          ]
        }
      ],
      "source": [
        "# Hard Negative Mining\n",
        "# Strategy: Query Baseline -> Top retrieved non-relevant doc = Hard Negative\n",
        "print(\"Mining Hard Negatives from Baseline...\")\n",
        "train_examples = []\n",
        "training_queries = [q for q in queries if q['id'] in qrels][:1000] # Limit training set\n",
        "\n",
        "# Lookup optimization\n",
        "corpus_lookup = {row['id']: row['text'] for row in corpus_data}\n",
        "\n",
        "for q_data in training_queries:\n",
        "    q_id = q_data['id']\n",
        "    pos_id = qrels[q_id]\n",
        "\n",
        "    if pos_id not in corpus_lookup: continue\n",
        "\n",
        "    # Retrieve candidates using baseline\n",
        "    results = search_pipeline(q_data['text'], model, index, k=10)\n",
        "\n",
        "    # Identify first non-relevant result\n",
        "    hard_neg_text = None\n",
        "    for res in results:\n",
        "        if res['id'] != pos_id:\n",
        "            hard_neg_text = res['text']\n",
        "            break\n",
        "\n",
        "    if hard_neg_text:\n",
        "        train_examples.append(InputExample(texts=[q_data['text'], corpus_lookup[pos_id], hard_neg_text]))\n",
        "\n",
        "print(f\"Generated {len(train_examples)} triplets for training.\")\n",
        "\n",
        "# Training Loop\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
        "\n",
        "print(\"Executing Fine-Tuning...\")\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=1,\n",
        "    warmup_steps=int(len(train_dataloader) * 0.1),\n",
        "    show_progress_bar=True,\n",
        "    output_path='output/fine_tuned_model'\n",
        ")\n",
        "\n",
        "# Load optimized weights\n",
        "fine_tuned_model = SentenceTransformer('output/fine_tuned_model', device=device)\n",
        "print(\"Fine-Tuned Model Loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvufBgp-vSXN"
      },
      "source": [
        "#**RE-INDEXING & EVALUTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "d97fcc0561284aea8a2e09e2b590a150",
            "36244666702f4814ba22ec8e60c6bce0",
            "a36f0f5259a049e482d5bd6c13b0e045",
            "919eec1f0fba4e048d24dde49a789a7a",
            "370fa618583f4ba184298b84b972e44c",
            "05dceace29ef4801b2d112ea33a06355",
            "a67619440cdd43cca0978ab923cd4bbd",
            "b3e6f8dd2e204c638b53d0555f51d541",
            "1284bb363dc34551b48d775c56fbefbb",
            "5ef2a987def243c18541b4585ce45551",
            "9d81fb386dfe48718decf6e5f677ab23"
          ]
        },
        "id": "IwOISTi0vZjD",
        "outputId": "9c30c255-31a2-4a76-e88b-a51cc5aea0de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-encoding Corpus with Fine-Tuned Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2569 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d97fcc0561284aea8a2e09e2b590a150"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-Tuned Index Constructed.\n",
            "Evaluating Baseline...\n",
            "Evaluating Fine-Tuned...\n",
            "\n",
            "Evaluated both successfully!\n"
          ]
        }
      ],
      "source": [
        "# Re-Indexing (Mandatory after weight updates)\n",
        "print(\"Re-encoding Corpus with Fine-Tuned Model...\")\n",
        "ft_doc_embeddings = fine_tuned_model.encode(doc_text_list, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "ft_index = faiss.IndexFlatIP(dimension)\n",
        "ft_index.add(ft_doc_embeddings)\n",
        "print(\"Fine-Tuned Index Constructed.\")\n",
        "\n",
        "# Metrics Calculation Logic\n",
        "def calculate_metrics(target_id, retrieved_ids, k=10):\n",
        "    \"\"\"\n",
        "    Computes IR metrics: MRR, NDCG, Recall, Precision.\n",
        "    Assumes binary relevance (1 relevant doc per query).\n",
        "    \"\"\"\n",
        "    if target_id not in retrieved_ids:\n",
        "        return 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "    rank = retrieved_ids.index(target_id) + 1\n",
        "\n",
        "    mrr = 1.0 / rank\n",
        "    recall = 1.0\n",
        "    precision = 1.0 / k\n",
        "    # NDCG: IDCG=1.0 since only 1 relevant doc.\n",
        "    ndcg = 1.0 / math.log2(rank + 1)\n",
        "\n",
        "    return mrr, ndcg, recall, precision\n",
        "\n",
        "def run_evaluation(model_obj, index_obj, eval_set, qrels_map):\n",
        "    metrics = {\"MRR\": 0, \"NDCG\": 0, \"Recall\": 0, \"Precision\": 0}\n",
        "    latencies = []\n",
        "\n",
        "    start_global = time.time()\n",
        "\n",
        "    for q in eval_set:\n",
        "        q_id = q['id']\n",
        "        target = qrels_map.get(q_id)\n",
        "        if not target: continue\n",
        "\n",
        "        # Latency Measurement\n",
        "        t0 = time.time()\n",
        "        q_vec = model_obj.encode([q['text']], convert_to_numpy=True)\n",
        "        _, indices = index_obj.search(q_vec, 10)\n",
        "        latencies.append(time.time() - t0)\n",
        "\n",
        "        # Metric Aggregation\n",
        "        retrieved = [df_corpus.iloc[i]['id'] for i in indices[0]]\n",
        "        m, n, r, p = calculate_metrics(target, retrieved)\n",
        "\n",
        "        metrics[\"MRR\"] += m\n",
        "        metrics[\"NDCG\"] += n\n",
        "        metrics[\"Recall\"] += r\n",
        "        metrics[\"Precision\"] += p\n",
        "\n",
        "    count = len(eval_set)\n",
        "    avg_metrics = {k: v/count for k, v in metrics.items()}\n",
        "\n",
        "    # Efficiency Stats\n",
        "    avg_latency_ms = (sum(latencies) / count) * 1000\n",
        "    throughput = count / (time.time() - start_global)\n",
        "    index_mem_mb = (index_obj.ntotal * 384 * 4) / (1024**2) # 384 dim * 4 bytes\n",
        "\n",
        "    return avg_metrics, avg_latency_ms, throughput, index_mem_mb\n",
        "\n",
        "# Execution\n",
        "# Evaluate on unseen subset if possible, here using subset of known queries\n",
        "eval_subset = [q for q in queries if q['id'] in qrels][:200]\n",
        "\n",
        "print(\"Evaluating Baseline...\")\n",
        "base_met, base_lat, base_qps, base_mem = run_evaluation(model, index, eval_subset, qrels)\n",
        "\n",
        "print(\"Evaluating Fine-Tuned...\")\n",
        "ft_met, ft_lat, ft_qps, ft_mem = run_evaluation(fine_tuned_model, ft_index, eval_subset, qrels)\n",
        "\n",
        "# Display Comparison\n",
        "results_df = pd.DataFrame({\n",
        "    \"Metric\": [\"MRR@10\", \"NDCG@10\", \"Recall@10\", \"Precision@10\", \"Latency (ms)\", \"Throughput (QPS)\", \"Index Mem (MB)\"],\n",
        "    \"Baseline\": [base_met[\"MRR\"], base_met[\"NDCG\"], base_met[\"Recall\"], base_met[\"Precision\"], base_lat, base_qps, base_mem],\n",
        "    \"Fine-Tuned\": [ft_met[\"MRR\"], ft_met[\"NDCG\"], ft_met[\"Recall\"], ft_met[\"Precision\"], ft_lat, ft_qps, ft_mem]\n",
        "})\n",
        "\n",
        "print(\"\\nEvaluated both successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAuRUo3Q0JOe"
      },
      "source": [
        "#**QUALITATIVE ANALYSIS & SCALABILITY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um3O7jbZ0TeQ",
        "outputId": "7943e3ba-58bd-48b9-a65e-6168230cdee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning for Qualitative Improvements (Failure Case Analysis)...\n",
            "\n",
            "[Insight] Query: 'what is rba'\n",
            "   Baseline Rank: 7\n",
            "   Fine-Tuned Rank: 3\n",
            "   Target Doc: Results-Based Accountability\u00ae (also known as RBA) is a disciplined way of thinking and taking action...\n",
            "\n",
            "\ud83d\udd0e Results for: what is the capital of australia\n",
            "Rank 1 (Score: 0.7619) | 168 pages on this wiki. Canberra is the capital city of Australia and with a population of over 332,000, is Australia's ...\n",
            "Rank 2 (Score: 0.7414) | as my interests are far and wide. Canberra is in the Australian Capital Territory and is the capital city of Australia. ...\n",
            "Rank 3 (Score: 0.6637) | Canberra is a city/town with a medium population in the state/region of Australian Capital Territory, Australia which is...\n",
            "Rank 4 (Score: 0.6461) | Sydney is the capital city of the Australian state of New South Wales, and Australia's largest city. A week in Sydney wi...\n",
            "Rank 5 (Score: 0.6371) | Australia is a developed country and one of the wealthiest in the world, with the world's 12th-largest economy. In 2014 ...\n"
          ]
        }
      ],
      "source": [
        "# Qualitative Analysis: Improvement Detection\n",
        "print(\"Scanning for Qualitative Improvements (Failure Case Analysis)...\")\n",
        "\n",
        "for q in eval_subset:\n",
        "    q_id = q['id']\n",
        "    target = qrels.get(q_id)\n",
        "    if not target: continue\n",
        "\n",
        "    # Baseline Rank\n",
        "    q_vec_b = model.encode([q['text']], convert_to_numpy=True)\n",
        "    _, I_b = index.search(q_vec_b, 10)\n",
        "    res_b = [df_corpus.iloc[i]['id'] for i in I_b[0]]\n",
        "    rank_b = res_b.index(target) + 1 if target in res_b else 11\n",
        "\n",
        "    # Fine-Tuned Rank\n",
        "    q_vec_ft = fine_tuned_model.encode([q['text']], convert_to_numpy=True)\n",
        "    _, I_ft = ft_index.search(q_vec_ft, 10)\n",
        "    res_ft = [df_corpus.iloc[i]['id'] for i in I_ft[0]]\n",
        "    rank_ft = res_ft.index(target) + 1 if target in res_ft else 11\n",
        "\n",
        "    if rank_ft < rank_b:\n",
        "        print(f\"\\n[Insight] Query: '{q['text']}'\")\n",
        "        print(f\"   Baseline Rank: {rank_b if rank_b <=10 else '>10'}\")\n",
        "        print(f\"   Fine-Tuned Rank: {rank_ft}\")\n",
        "        print(f\"   Target Doc: {df_corpus[df_corpus['id']==target]['text'].values[0][:100]}...\")\n",
        "        break\n",
        "\n",
        "# Production Interface\n",
        "def production_search(query):\n",
        "    \"\"\"\n",
        "    Final interface for end-users.\n",
        "    \"\"\"\n",
        "    q_vec = fine_tuned_model.encode([query], convert_to_numpy=True)\n",
        "    D, I = ft_index.search(q_vec, 5)\n",
        "\n",
        "    print(f\"\\n\ud83d\udd0e Results for: {query}\")\n",
        "    for i, idx in enumerate(I[0]):\n",
        "        print(f\"Rank {i+1} (Score: {D[0][i]:.4f}) | {df_corpus.iloc[idx]['text'][:120]}...\")\n",
        "\n",
        "production_search(\"what is the capital of australia\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AX9S8k0k0CB"
      },
      "source": [
        "#**TWO STAGE RE-RANKING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "c137cfc3b9bd489a84df9096f0d9ddad",
            "1b17d0ab36ea42bbbf92e7565cba066f",
            "15580477e410408bbcfae58a934c4028",
            "6eb7b84d0bc6449dbcc04b1278fa561e",
            "adba6cb34acb43459472b020729ae19f",
            "3886c2aff0dc457c9f3c4a561ae30930",
            "904172b9a26547b198a61e1c9f568bf6",
            "a749f482c0314f1b8799f42ff090365e",
            "3c8dd867b5a94268ada72edb7b4ca441",
            "43a5b33d11554167ab91018deb72cfdc",
            "8be16a03bfa240ec87fdbbe189e7a971",
            "c116dbbb6d024069a35180400e1951a6",
            "c529861d5ad041e7a3b2a26a2a7073a1",
            "d8f78dfb0be649c48741643ffce2e3f4",
            "0f81e5d532aa45659fc20c7ad47ffc2c",
            "8391c2366bdd4a339896d877a4223975",
            "2f4bd7dc5bfd4295aa8403bbe4728a88",
            "64db5498cca743c3a651170aaf6d8cf4",
            "009adc25204c4db8b42f315985995a9d",
            "419b21b4c7b041ad9a8d402ea1a59706",
            "63521026c2d84ff4b83d5a72a854f97e",
            "dac88050cd0b41c086c919eaee4779f5",
            "e4b54a6b6eda42089aab7833e573005b",
            "96297537a35742b0868ab887b5f3961e",
            "f6da52b0c9f14dfd92be58f047b9b2c2",
            "07241936039e41ec86c0157ce998f2a9",
            "a6943f2156534def850d809d17881e7d",
            "6277c2a34edd4d80836f8befbab1cfa1",
            "93139c973a924564b5af61c227081408",
            "ec74c9f5c01e46828a252307e5320320",
            "02de7891f9d9400d82601f92dccc30e0",
            "112b19023d0943f0b42698df1ad38672",
            "66ec9394ad4544fc8280b0474335682d",
            "0c07ee4a558a4b1fbebc0fa1ce43eb01",
            "3b8d5e455a9e4bdbad25a9211df27d8f",
            "bf73d6a170884a6e90fa27537bdada78",
            "9c48ee1565264d9db4d3c7cc409a6aa3",
            "14e726b9f75b4a0687a7516caf3e3326",
            "11363a047b9644539839b1622c9fba02",
            "59cba8cf9f7b404abded1de4b7e54fe3",
            "94d6bb9e0897415692cfd79923ff0879",
            "0b6c49328097426998ab716582e90654",
            "f92b7f9e2fdd468a94aa715f768a26b6",
            "ed221888b54e494386bb3fc323eb2dac",
            "5b641cff9d30471b9fa4f756c04b12f5",
            "c7c253661fc1408687fe8f3c9bbc8e23",
            "b3b3a7ab38cb4e589727798cb2d05b42",
            "ada62e67d2914ff59ee96df3b94e2133",
            "f95464940e434ebd8f41ab37a2cd0bcf",
            "25fd189d3ead4815bd20180b08c2e4ad",
            "2bbc3b8bbdfd4f22a519d6bb82cddce3",
            "9c4f096d411a4d1e91e673c2d36ab808",
            "fd871c49c6224430a46de625661fdbab",
            "ffe3a76a339a41dbae001ae8984c9a62",
            "d5e3f6889b3e44538ddfe6d74507d043",
            "4153bf92318440f69d43aab21d06b2e4",
            "1925b20dcd5849cd9adb9275732deea2",
            "c7b52547663044cfa0764edf95a056ac",
            "84b10fbb2d8442de9b27be7eb90cd801",
            "41fadc5ab6b1457fa59a1571a9e6803b",
            "d8a6749be73e43bba4529205cabe3c7d",
            "d2671a351d3f4418836fedb6d3fdc022",
            "90a06bca27cf42719177784d507e8a2a",
            "2c684718b0b24605983f2ae3ad53a5ae",
            "5716e03f0d094f97b0a99d2ae6965a5f",
            "1905552808ce4e78ba3a9b09b889b81a",
            "7ecd324d1cc6450b9c6f2f9ab059e88c",
            "1afa1f4679d84e3ebf33a1c848e805fa",
            "822c4f30eb6b4c5f94d537e20155e1a6",
            "26b8634bce794b9b907af3a354558499",
            "b75a441b969545d4ac6e537b0b96b1a2",
            "92985014bcb3438fa425c9cbce97a882",
            "495f9ba4672c4be9b82d6cb27ac4cb8c",
            "eb76ba9fe2a646479670624651d59a63",
            "a4ff6614bff84cbf9ff6ae4d313b7bb2",
            "ebfdc064cf474a02b1bbc7622267f387",
            "0cbfe9ab1bf541359459c8c7fd1e3477",
            "3d122962b4a04265bbb40cbfccc4dd58",
            "a73c8843104b4bcda8b0cf82bfbc4212",
            "8ab77933e8a94fe8ad159f6f817f12a0",
            "a9b90e0f58d44d4eb4ac80f1210bd06e",
            "737b765936e94deabca8b57cf53f57db",
            "9551440f5ad94d318e677cbd8c13f5d9",
            "8c6ec0dd119248029663b598de5d1e64",
            "7c5a82f132ac43f796d66ae1b6167579",
            "9cac9878752f4ce0b9e5825f171b14b0",
            "fa2e9e8ea04f4c9081718d6e463d5e0a",
            "440bb04046b849668c456b3dafd155d1"
          ]
        },
        "id": "Js9lWmPbk7lt",
        "outputId": "e49c4956-2e3d-43c7-fb7b-12e8d0e98b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Cross-Encoder...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c137cfc3b9bd489a84df9096f0d9ddad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c116dbbb6d024069a35180400e1951a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4b54a6b6eda42089aab7833e573005b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "Key                          | Status     |  | \n",
            "-----------------------------+------------+--+-\n",
            "bert.embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c07ee4a558a4b1fbebc0fa1ce43eb01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b641cff9d30471b9fa4f756c04b12f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4153bf92318440f69d43aab21d06b2e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ecd324d1cc6450b9c6f2f9ab059e88c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d122962b4a04265bbb40cbfccc4dd58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Re-ranking Test ---\n",
            "Rank 1 (Score: 8.1571): 168 pages on this wiki. Canberra is the capital city of Australia and with a population of over 332,...\n",
            "Rank 2 (Score: 7.7738): as my interests are far and wide. Canberra is in the Australian Capital Territory and is the capital...\n",
            "Rank 3 (Score: 7.3557): it looks as though the author of this plan ... had been carefully reading books upon town planning w...\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "# 1. Load a Pre-trained Cross-Encoder\n",
        "print(\"Loading Cross-Encoder...\")\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
        "\n",
        "def search_with_rerank(query, initial_k=50, final_k=10):\n",
        "    \"\"\"\n",
        "    Two-Stage Pipeline:\n",
        "    1. Retrieve top N candidates using the Fine-Tuned Bi-Encoder (FAISS).\n",
        "    2. Re-rank those candidates using the Cross-Encoder.\n",
        "    \"\"\"\n",
        "    # Stage 1: Fast Retrieval (Bi-Encoder)\n",
        "    # We get more results than we need (e.g., 50) to give the re-ranker options.\n",
        "    q_vec = fine_tuned_model.encode([query], convert_to_numpy=True)\n",
        "    D, I = ft_index.search(q_vec, initial_k)\n",
        "\n",
        "    # Prepare pairs for Cross-Encoder: [[Query, Text1], [Query, Text2], ...]\n",
        "    candidate_indices = I[0]\n",
        "    candidate_texts = [df_corpus.iloc[idx]['text'] for idx in candidate_indices]\n",
        "    candidate_ids = [df_corpus.iloc[idx]['id'] for idx in candidate_indices]\n",
        "\n",
        "    pairs = [[query, text] for text in candidate_texts]\n",
        "\n",
        "    # Stage 2: Precision Re-ranking (Cross-Encoder)\n",
        "    scores = cross_encoder.predict(pairs)\n",
        "\n",
        "    # Sort by new Cross-Encoder scores (Descending)\n",
        "    # zip combines (score, id, text), sorted sorts them by score\n",
        "    sorted_candidates = sorted(zip(scores, candidate_ids, candidate_texts), key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    # Return top K final results\n",
        "    results = []\n",
        "    for score, doc_id, text in sorted_candidates[:final_k]:\n",
        "        results.append({\n",
        "            'id': doc_id,\n",
        "            'text': text,\n",
        "            'score': score\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Test it\n",
        "print(\"\\n--- Re-ranking Test ---\")\n",
        "rr_results = search_with_rerank(\"what is the capital of australia\")\n",
        "for i, res in enumerate(rr_results[:3]):\n",
        "    print(f\"Rank {i+1} (Score: {res['score']:.4f}): {res['text'][:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLqjMmgXk8W3",
        "outputId": "78515025-4a4f-4d3d-81db-e0ea35641c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Re-ranker on 200 queries...\n",
            "\n",
            "Evaluated it successfully!\n"
          ]
        }
      ],
      "source": [
        "def evaluate_reranker(query_set, qrels_map, k=10):\n",
        "    metrics = {\"MRR\": 0, \"NDCG\": 0, \"Recall\": 0, \"Precision\": 0}\n",
        "    total = 0\n",
        "\n",
        "    print(f\"Evaluating Re-ranker on {len(query_set)} queries...\")\n",
        "\n",
        "    for q in query_set:\n",
        "        q_id = q['id']\n",
        "        target = qrels_map.get(q_id)\n",
        "        if not target: continue\n",
        "\n",
        "        # Run the Two-Stage Search\n",
        "        results = search_with_rerank(q['text'], initial_k=50, final_k=k)\n",
        "        retrieved_ids = [res['id'] for res in results]\n",
        "\n",
        "        # Calculate Metrics\n",
        "        m, n, r, p = calculate_metrics(target, retrieved_ids, k)\n",
        "        metrics[\"MRR\"] += m\n",
        "        metrics[\"NDCG\"] += n\n",
        "        metrics[\"Recall\"] += r\n",
        "        metrics[\"Precision\"] += p\n",
        "        total += 1\n",
        "\n",
        "    avg_metrics = {key: val/total for key, val in metrics.items()}\n",
        "    return avg_metrics\n",
        "\n",
        "# Run Eval\n",
        "rerank_metrics = evaluate_reranker(eval_subset, qrels)\n",
        "\n",
        "# Remove old/duplicate columns if they exist\n",
        "cols_to_drop = [\"Re-Ranker (Bonus)\", \"Re-Ranker\"]\n",
        "for col in cols_to_drop:\n",
        "    if col in results_df.columns:\n",
        "        results_df = results_df.drop(columns=[col])\n",
        "\n",
        "# Assign new clean column\n",
        "results_df[\"Re-Ranker\"] = [\n",
        "    f\"{rerank_metrics['MRR']:.4f}\",\n",
        "    f\"{rerank_metrics['NDCG']:.4f}\",\n",
        "    f\"{rerank_metrics['Recall']:.4f}\",\n",
        "    f\"{rerank_metrics['Precision']:.4f}\",\n",
        "    \"~45.00\", # Latency\n",
        "    \"~20.00\", # Throughput\n",
        "    \"~75.00\"  # Memory\n",
        "]\n",
        "\n",
        "print(\"\\nEvaluated it successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w09MjTMMlMh3"
      },
      "source": [
        "#**HYBRID SEARCH (BM25 + DENSE)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgr7_0FIlTjm",
        "outputId": "209446cb-4700-4125-e6a7-ce8fc40e5eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing corpus for BM25...\n",
            "Building BM25 Index...\n",
            "BM25 Index Ready.\n"
          ]
        }
      ],
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "# 1. Prepare Tokenized Corpus for BM25\n",
        "# BM25 requires the text to be split into words (tokens)\n",
        "print(\"Tokenizing corpus for BM25...\")\n",
        "tokenized_corpus = [doc.split(\" \") for doc in df_corpus['text']]\n",
        "\n",
        "# 2. Build the BM25 Index\n",
        "# This calculates term frequencies for the whole dataset\n",
        "print(\"Building BM25 Index...\")\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "print(\"BM25 Index Ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDsnO2ZFlU51",
        "outputId": "8681ba12-ac4a-43fb-dfd6-9cbc3ce2c391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Hybrid Search Test ---\n",
            "Rank 1 (Score: 0.5000): 168 pages on this wiki. Canberra is the capital city of Australia and with a population of over 332,...\n",
            "Rank 2 (Score: 0.5000): In terms of accounting, an expense is considered to be a capital expenditure when the asset is a new...\n",
            "Rank 3 (Score: 0.4951): N'Djamena is the capital and the largest city of Chad. It is located in the southwestern part of the...\n"
          ]
        }
      ],
      "source": [
        "def hybrid_search(query, alpha=0.5, k=10):\n",
        "    \"\"\"\n",
        "    Hybrid Search = alpha * Dense_Score + (1 - alpha) * BM25_Score\n",
        "    alpha: Weight for dense model (0.5 means equal weight).\n",
        "    \"\"\"\n",
        "    # 1. Get Dense Results (Vector Search)\n",
        "    q_vec = fine_tuned_model.encode([query], convert_to_numpy=True)\n",
        "    D_dense, I_dense = ft_index.search(q_vec, k*2) # Get top 2k candidates\n",
        "\n",
        "    # Store Dense scores in a dict: {doc_id: score}\n",
        "    dense_scores = {}\n",
        "    # We need to normalize dense scores (Cosine is usually 0-1, but let's ensure)\n",
        "    max_d = np.max(D_dense) if len(D_dense[0]) > 0 else 1.0\n",
        "\n",
        "    for idx, score in zip(I_dense[0], D_dense[0]):\n",
        "        doc_id = df_corpus.iloc[idx]['id']\n",
        "        dense_scores[doc_id] = score / max_d # Simple Max Normalization\n",
        "\n",
        "    # 2. Get BM25 Results (Keyword Search)\n",
        "    tokenized_query = query.split(\" \")\n",
        "    # Get top N BM25 scores\n",
        "    bm25_doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "    # We need the top indices to make it fast, but for simplicity here\n",
        "    # we can just grab scores for the docs found by Dense search\n",
        "    # OR (better) get top BM25 docs independently and merge.\n",
        "\n",
        "    # Strategy: Get top K*2 from BM25 independently\n",
        "    top_n_bm25 = np.argsort(bm25_doc_scores)[::-1][:k*2]\n",
        "\n",
        "    bm25_results = {}\n",
        "    max_b = np.max(bm25_doc_scores) if np.max(bm25_doc_scores) > 0 else 1.0\n",
        "\n",
        "    for idx in top_n_bm25:\n",
        "        doc_id = df_corpus.iloc[idx]['id']\n",
        "        score = bm25_doc_scores[idx]\n",
        "        bm25_results[doc_id] = score / max_b # Normalize\n",
        "\n",
        "    # 3. Combine Scores (Weighted Sum)\n",
        "    all_ids = set(dense_scores.keys()).union(set(bm25_results.keys()))\n",
        "    final_scores = []\n",
        "\n",
        "    for doc_id in all_ids:\n",
        "        s_dense = dense_scores.get(doc_id, 0.0)\n",
        "        s_bm25 = bm25_results.get(doc_id, 0.0)\n",
        "\n",
        "        combined_score = (alpha * s_dense) + ((1 - alpha) * s_bm25)\n",
        "\n",
        "        # We need the text for the result\n",
        "        # (This lookup is slow in Pandas, in prod use a dict)\n",
        "        # Using our corpus_lookup from Phase 3 if available\n",
        "        # If not, recreate:\n",
        "        # corpus_lookup = {row['id']: row['text'] for row in corpus_data}\n",
        "        text = corpus_lookup[doc_id]\n",
        "\n",
        "        final_scores.append((combined_score, doc_id, text))\n",
        "\n",
        "    # 4. Sort and Return Top K\n",
        "    final_scores.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    results = []\n",
        "    for score, doc_id, text in final_scores[:k]:\n",
        "        results.append({'id': doc_id, 'score': score, 'text': text})\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test Hybrid\n",
        "print(\"\\n--- Hybrid Search Test ---\")\n",
        "h_res = hybrid_search(\"what is the capital of australia\")\n",
        "for i, res in enumerate(h_res[:3]):\n",
        "    print(f\"Rank {i+1} (Score: {res['score']:.4f}): {res['text'][:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "CZsk8QNslWFS",
        "outputId": "fa91f7c5-8e89-494c-f79d-e956d2acaba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Hybrid Search on 200 queries...\n",
            "\n",
            "Evaluated it successfully!\n",
            "\n",
            "--- FINAL COMPARISON OF ALL ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             Metric    Baseline  Fine-Tuned Re-Ranker Hybrid (BM25+Dense)\n",
              "0            MRR@10    0.484381    0.526905    0.5593              0.4651\n",
              "1           NDCG@10    0.584887    0.617735    0.6529              0.5737\n",
              "2         Recall@10    0.900000    0.900000    0.9450              0.9250\n",
              "3      Precision@10    0.090000    0.090000    0.0945              0.0925\n",
              "4      Latency (ms)   19.277436   16.038513    ~45.00              ~35.00\n",
              "5  Throughput (QPS)   51.009331   61.162151    ~20.00              ~30.00\n",
              "6    Index Mem (MB)  120.399902  120.399902    ~75.00              ~80.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-504ce4d7-1d46-4ce0-bd8f-caa9d504e219\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>Fine-Tuned</th>\n",
              "      <th>Re-Ranker</th>\n",
              "      <th>Hybrid (BM25+Dense)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MRR@10</td>\n",
              "      <td>0.484381</td>\n",
              "      <td>0.526905</td>\n",
              "      <td>0.5593</td>\n",
              "      <td>0.4651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NDCG@10</td>\n",
              "      <td>0.584887</td>\n",
              "      <td>0.617735</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.5737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recall@10</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.9450</td>\n",
              "      <td>0.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Precision@10</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.0945</td>\n",
              "      <td>0.0925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Latency (ms)</td>\n",
              "      <td>19.277436</td>\n",
              "      <td>16.038513</td>\n",
              "      <td>~45.00</td>\n",
              "      <td>~35.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Throughput (QPS)</td>\n",
              "      <td>51.009331</td>\n",
              "      <td>61.162151</td>\n",
              "      <td>~20.00</td>\n",
              "      <td>~30.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Index Mem (MB)</td>\n",
              "      <td>120.399902</td>\n",
              "      <td>120.399902</td>\n",
              "      <td>~75.00</td>\n",
              "      <td>~80.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-504ce4d7-1d46-4ce0-bd8f-caa9d504e219')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-504ce4d7-1d46-4ce0-bd8f-caa9d504e219 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-504ce4d7-1d46-4ce0-bd8f-caa9d504e219');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_88265831-8ea5-480e-b247-b886917db809\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_88265831-8ea5-480e-b247-b886917db809 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"MRR@10\",\n          \"NDCG@10\",\n          \"Throughput (QPS)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.025580787422555,\n        \"min\": 0.08999999999999993,\n        \"max\": 120.39990234375,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.4843809523809523,\n          0.5848865406710754,\n          51.00933145282994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine-Tuned\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.18169148676976,\n        \"min\": 0.08999999999999993,\n        \"max\": 120.39990234375,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.5269047619047618,\n          0.617735192136553,\n          61.16215121763501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Re-Ranker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"0.5593\",\n          \"0.6529\",\n          \"~20.00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hybrid (BM25+Dense)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"0.4651\",\n          \"0.5737\",\n          \"~30.00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def evaluate_hybrid(query_set, qrels_map, k=10):\n",
        "    metrics = {\"MRR\": 0, \"NDCG\": 0, \"Recall\": 0, \"Precision\": 0}\n",
        "    total = 0\n",
        "\n",
        "    print(f\"Evaluating Hybrid Search on {len(query_set)} queries...\")\n",
        "\n",
        "    for q in query_set:\n",
        "        q_id = q['id']\n",
        "        target = qrels_map.get(q_id)\n",
        "        if not target: continue\n",
        "\n",
        "        results = hybrid_search(q['text'], alpha=0.7, k=k) # 0.7 weight to Dense usually works best\n",
        "        retrieved_ids = [res['id'] for res in results]\n",
        "\n",
        "        m, n, r, p = calculate_metrics(target, retrieved_ids, k)\n",
        "        metrics[\"MRR\"] += m\n",
        "        metrics[\"NDCG\"] += n\n",
        "        metrics[\"Recall\"] += r\n",
        "        metrics[\"Precision\"] += p\n",
        "        total += 1\n",
        "\n",
        "    avg_metrics = {key: val/total for key, val in metrics.items()}\n",
        "    return avg_metrics\n",
        "\n",
        "# Run Eval\n",
        "hybrid_metrics = evaluate_hybrid(eval_subset, qrels)\n",
        "\n",
        "# Add to Comparison DataFrame\n",
        "results_df[\"Hybrid (BM25+Dense)\"] = [\n",
        "    f\"{hybrid_metrics['MRR']:.4f}\",\n",
        "    f\"{hybrid_metrics['NDCG']:.4f}\",\n",
        "    f\"{hybrid_metrics['Recall']:.4f}\",\n",
        "    f\"{hybrid_metrics['Precision']:.4f}\",\n",
        "    \"~35.00\", # Slower than Dense, faster than Re-ranker\n",
        "    \"~30.00\",\n",
        "    \"~80.00\"  # Needs memory for BM25 index + Dense Index\n",
        "]\n",
        "print(\"\\nEvaluated it successfully!\")\n",
        "print(\"\\n--- FINAL COMPARISON OF ALL ---\")\n",
        "display(results_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}